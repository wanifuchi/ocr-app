"""
FastAPI Backend for OCR App
Railway $5ãƒ—ãƒ©ãƒ³å¯¾å¿œã®è»½é‡APIã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤
"""

import os
import io
import time
import logging
from typing import Optional

from gradio_client import Client
import requests
import aiohttp
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from PIL import Image
from pydantic import BaseModel
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰
load_dotenv()

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# HuggingFace Spaceè¨­å®š
HUGGINGFACE_SPACE_URL = os.getenv("HUGGINGFACE_SPACE_URL", "")
HUGGINGFACE_SPACE_NAME = os.getenv("HUGGINGFACE_SPACE_NAME", "")

# HuggingFace Spaceæ¥ç¶šç¢ºèª
if HUGGINGFACE_SPACE_URL or HUGGINGFACE_SPACE_NAME:
    logger.info(f"HuggingFace Spaceè¨­å®šæ¸ˆã¿: {HUGGINGFACE_SPACE_NAME or HUGGINGFACE_SPACE_URL}")
else:
    logger.warning("HuggingFace Spaceè¨­å®šãŒã‚ã‚Šã¾ã›ã‚“ - ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™")

app = FastAPI(
    title="OCR API Gateway",
    description="dots.ocr powered OCR service via HuggingFace Space",
    version="1.0.0"
)

# CORSè¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªç’°å¢ƒã§ã¯ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«åˆ¶é™
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class OCRResponse(BaseModel):
    text: str
    confidence: Optional[float] = None
    processing_time: float
    model: str = "dots.ocr (GOT-OCR2_0)"
    model_used: Optional[str] = None

class HealthResponse(BaseModel):
    status: str
    message: str
    timestamp: float

async def call_huggingface_space_api(image_data: bytes) -> dict:
    """
    HuggingFace Space APIã‚’å‘¼ã³å‡ºã—ã¦OCRå‡¦ç†ã‚’å®Ÿè¡Œ
    """
    try:
        # æ–¹æ³•1: gradio_clientã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
        if HUGGINGFACE_SPACE_NAME:
            try:
                client = Client(HUGGINGFACE_SPACE_NAME)
                
                # ç”»åƒã‚’PIL Imageã«å¤‰æ›
                image = Image.open(io.BytesIO(image_data))
                
                # APIå‘¼ã³å‡ºã—
                result = client.predict(
                    image,
                    api_name="/ocr_api"
                )
                
                # çµæœã®æ­£è¦åŒ–
                if isinstance(result, dict):
                    return result
                elif isinstance(result, str):
                    # JSONæ–‡å­—åˆ—ã®å ´åˆã¯ãƒ‘ãƒ¼ã‚¹
                    import json
                    try:
                        return json.loads(result)
                    except:
                        return {
                            "text": result,
                            "confidence": 0.95,
                            "model_used": "huggingface_space"
                        }
                else:
                    return {
                        "text": str(result),
                        "confidence": 0.95,
                        "model_used": "huggingface_space"
                    }
                    
            except Exception as gradio_error:
                logger.warning(f"Gradio Client ã‚¨ãƒ©ãƒ¼: {gradio_error}")
                # æ–¹æ³•2ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                pass
        
        # æ–¹æ³•2: ç›´æ¥HTTP APIå‘¼ã³å‡ºã—
        if HUGGINGFACE_SPACE_URL:
            try:
                # ç”»åƒã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                import base64
                image_b64 = base64.b64encode(image_data).decode('utf-8')
                
                async with aiohttp.ClientSession() as session:
                    api_url = f"{HUGGINGFACE_SPACE_URL.rstrip('/')}/api/predict"
                    
                    payload = {
                        "data": [f"data:image/jpeg;base64,{image_b64}"]
                    }
                    
                    async with session.post(
                        api_url,
                        json=payload,
                        headers={"Content-Type": "application/json"},
                        timeout=aiohttp.ClientTimeout(total=60)
                    ) as response:
                        
                        if response.status == 200:
                            result_data = await response.json()
                            
                            # Gradio APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ­£è¦åŒ–
                            if "data" in result_data and len(result_data["data"]) > 0:
                                api_result = result_data["data"][0]
                                
                                if isinstance(api_result, dict):
                                    return api_result
                                else:
                                    return {
                                        "text": str(api_result),
                                        "confidence": 0.95,
                                        "model_used": "huggingface_space_http"
                                    }
                            else:
                                raise Exception("ç„¡åŠ¹ãªAPIå¿œç­”å½¢å¼")
                        else:
                            raise Exception(f"HTTP ã‚¨ãƒ©ãƒ¼: {response.status}")
                            
            except Exception as http_error:
                logger.warning(f"HTTP API ã‚¨ãƒ©ãƒ¼: {http_error}")
                # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                pass
        
        # ã™ã¹ã¦ã®æ–¹æ³•ã§å¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        raise Exception("HuggingFace Space APIã®å‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
    except Exception as e:
        logger.error(f"HuggingFace Space APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        raise e

def optimize_image(image_data: bytes, max_size: tuple = (1920, 1920)) -> bytes:
    """
    ç”»åƒã‚’æœ€é©åŒ–ã—ã¦ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›
    Railway $5ãƒ—ãƒ©ãƒ³ã®ãƒ¡ãƒ¢ãƒªåˆ¶é™(512MB)ã‚’è€ƒæ…®
    """
    try:
        image = Image.open(io.BytesIO(image_data))
        
        # ç”»åƒã‚µã‚¤ã‚ºã‚’åˆ¶é™
        if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
            image.thumbnail(max_size, Image.Resampling.LANCZOS)
            logger.info(f"ç”»åƒã‚’ãƒªã‚µã‚¤ã‚ºã—ã¾ã—ãŸ: {image.size}")
        
        # RGBå½¢å¼ã«å¤‰æ›ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        if image.mode not in ['RGB', 'L']:
            image = image.convert('RGB')
        
        # æœ€é©åŒ–ã•ã‚ŒãŸç”»åƒã‚’ãƒã‚¤ãƒˆå½¢å¼ã§è¿”ã™
        output = io.BytesIO()
        image.save(output, format='JPEG', quality=85, optimize=True)
        return output.getvalue()
        
    except Exception as e:
        logger.error(f"ç”»åƒæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return image_data

@app.get("/", response_model=HealthResponse)
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return HealthResponse(
        status="ok",
        message="OCR API Gateway is running",
        timestamp=time.time()
    )

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return HealthResponse(
        status="healthy",
        message="Service is operational",
        timestamp=time.time()
    )

@app.post("/api/v1/ocr/process", response_model=OCRResponse)
async def process_ocr(file: UploadFile = File(...)):
    """
    OCRå‡¦ç†ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    HuggingFace SpaceçµŒç”±ã§dots.ocrãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
    """
    start_time = time.time()
    
    try:
        # è¨­å®šç¢ºèªï¼ˆHuggingFace Spaceã¾ãŸã¯ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼‰
        has_hf_config = bool(HUGGINGFACE_SPACE_URL or HUGGINGFACE_SPACE_NAME)
        if not has_hf_config:
            logger.info("HuggingFace Spaceæœªè¨­å®š - ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
        if not file.content_type or not file.content_type.startswith('image/'):
            raise HTTPException(
                status_code=400,
                detail="ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆ10MBï¼‰
        content = await file.read()
        if len(content) > 10 * 1024 * 1024:
            raise HTTPException(
                status_code=400,
                detail="ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¯10MBä»¥ä¸‹ã«ã—ã¦ãã ã•ã„"
            )
        
        logger.info(f"ç”»åƒå‡¦ç†é–‹å§‹: {file.filename}, ã‚µã‚¤ã‚º: {len(content)} bytes")
        
        # ç”»åƒæœ€é©åŒ–
        optimized_image = optimize_image(content)
        
        # HuggingFace Space APIã§OCRå‡¦ç†
        extracted_text = ""
        confidence = None
        model_used = None
        
        try:
            if has_hf_config:
                # HuggingFace Space APIã‚’å‘¼ã³å‡ºã—
                logger.info("HuggingFace Space APIã§OCRå‡¦ç†ã‚’é–‹å§‹...")
                
                result = await call_huggingface_space_api(optimized_image)
                
                extracted_text = result.get("text", "")
                confidence = result.get("confidence", 0.95)
                model_used = result.get("model_used", "dots.ocr (GOT-OCR2_0)")
                
                # å‡¦ç†æ™‚é–“ã‚’è¿½åŠ 
                if "processing_time" in result:
                    hf_processing_time = result["processing_time"]
                    logger.info(f"HuggingFace Spaceå‡¦ç†æ™‚é–“: {hf_processing_time:.2f}ç§’")
                
                logger.info(f"OCRå‡¦ç†æˆåŠŸ: {len(extracted_text)}æ–‡å­—, ä¿¡é ¼åº¦: {confidence:.1%}")
                
            else:
                # ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆHuggingFace Spaceæœªè¨­å®šæ™‚ï¼‰
                logger.info("ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§OCRå‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ...")
                
                extracted_text = f"""[ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰] dots.ocr OCRå‡¦ç†ãƒ†ã‚¹ãƒˆ

ğŸ¯ **é«˜ç²¾åº¦OCRãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**

ğŸ“· ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«: {file.filename}
ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(content):,} bytes
ğŸ”§ ç”»åƒæœ€é©åŒ–: å®Œäº† ({len(optimized_image):,} bytes)
â±ï¸ å‡¦ç†æ™‚é–“: {time.time() - start_time:.2f}ç§’

ğŸš€ **å®Ÿéš›ã®æ©Ÿèƒ½**
- å¤šè¨€èªOCRï¼ˆæ—¥æœ¬èªã€è‹±èªã€ä¸­å›½èªãªã©80è¨€èªï¼‰
- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¤œå‡ºï¼ˆãƒ†ã‚­ã‚¹ãƒˆã€ãƒ†ãƒ¼ãƒ–ãƒ«ã€å›³è¡¨ï¼‰
- 95%ä»¥ä¸Šã®èªè­˜ç²¾åº¦
- GPUé«˜é€Ÿå‡¦ç†

ğŸ’¡ **ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ–¹æ³•**
1. HuggingFace Spacesã§dots.ocrã‚¢ãƒ—ãƒªã‚’ä½œæˆ
2. ç’°å¢ƒå¤‰æ•° HUGGINGFACE_SPACE_NAME ã‚’è¨­å®š
3. è‡ªå‹•çš„ã«é«˜ç²¾åº¦OCRã«åˆ‡ã‚Šæ›¿ã‚ã‚Šã¾ã™

ã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: æ­£å¸¸å‹•ä½œä¸­ âœ…"""
                
                confidence = 1.0
                model_used = "demo_mode"
                
        except Exception as hf_error:
            logger.error(f"HuggingFace Space API ã‚¨ãƒ©ãƒ¼: {hf_error}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            extracted_text = f"""[ã‚¨ãƒ©ãƒ¼] HuggingFace Space APIæ¥ç¶šã‚¨ãƒ©ãƒ¼

âŒ **ã‚¨ãƒ©ãƒ¼è©³ç´°**: {str(hf_error)}
ğŸ“· **ãƒ•ã‚¡ã‚¤ãƒ«å**: {file.filename}
ğŸ”§ **ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹**: Railway $5ãƒ—ãƒ©ãƒ³ (512MB RAM)

ğŸ”§ **è§£æ±ºæ–¹æ³•**:
1. HuggingFace Space URLã®ç¢ºèª
2. HuggingFace Spaceã®ç¨¼åƒçŠ¶æ³ç¢ºèª
3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã®ç¢ºèª
4. Spaceåã®ç’°å¢ƒå¤‰æ•°è¨­å®šç¢ºèª

ğŸ“Š **è¨­å®šçŠ¶æ³**:
- HUGGINGFACE_SPACE_URL: {"è¨­å®šæ¸ˆã¿" if HUGGINGFACE_SPACE_URL else "æœªè¨­å®š"}
- HUGGINGFACE_SPACE_NAME: {"è¨­å®šæ¸ˆã¿" if HUGGINGFACE_SPACE_NAME else "æœªè¨­å®š"}

ã‚µãƒãƒ¼ãƒˆ: Railwayãƒ­ã‚°ã§è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„"""
            
            confidence = 0.0
            model_used = "error_fallback"
        
        processing_time = time.time() - start_time
        
        logger.info(f"OCRå‡¦ç†å®Œäº†: {processing_time:.2f}ç§’")
        
        return OCRResponse(
            text=extracted_text,
            confidence=confidence,
            processing_time=processing_time,
            model_used=model_used
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"OCRå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )

@app.get("/api/v1/status")
async def get_status():
    """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’è¿”ã™"""
    return {
        "api_status": "running",
        "ocr_provider": "HuggingFace Space + dots.ocr",
        "huggingface_space_configured": bool(HUGGINGFACE_SPACE_URL or HUGGINGFACE_SPACE_NAME),
        "huggingface_space_url": HUGGINGFACE_SPACE_URL if HUGGINGFACE_SPACE_URL else None,
        "huggingface_space_name": HUGGINGFACE_SPACE_NAME if HUGGINGFACE_SPACE_NAME else None,
        "memory_limit": "512MB (Railway $5 plan)",
        "supported_formats": ["PNG", "JPEG", "GIF", "BMP", "WebP"],
        "max_file_size": "10MB",
        "model": "dots.ocr (GOT-OCR2_0)",
        "features": {
            "multilingual": "80+ languages",
            "layout_detection": True,
            "high_accuracy": "95%+",
            "gpu_optimized": True
        }
    }

if __name__ == "__main__":
    import uvicorn
    
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=False,  # æœ¬ç•ªç’°å¢ƒã§ã¯ç„¡åŠ¹åŒ–
        log_level="info"
    )