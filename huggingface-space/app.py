"""
HuggingFace Space for dots.ocr (GOT-OCR2_0)
é«˜ç²¾åº¦OCRãƒ¢ãƒ‡ãƒ«ã‚’APIã¨ã—ã¦æä¾›
"""

import gradio as gr
import torch
import os
import io
import base64
import json
import time
from PIL import Image
from transformers import AutoModel, AutoTokenizer
import logging

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# GPUä½¿ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
logger.info(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
model = None
tokenizer = None

def load_model():
    """dots.ocrãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    global model, tokenizer
    
    try:
        logger.info("dots.ocr (GOT-OCR2_0) ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’èª­ã¿è¾¼ã¿
        model = AutoModel.from_pretrained(
            'ucaslcl/GOT-OCR2_0', 
            trust_remote_code=True, 
            low_cpu_mem_usage=True, 
            device_map='auto',
            use_safetensors=True,
            pad_token_id=151643
        ).eval().cuda()
        
        tokenizer = AutoTokenizer.from_pretrained(
            'ucaslcl/GOT-OCR2_0', 
            trust_remote_code=True
        )
        
        logger.info("ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        return True
        
    except Exception as e:
        logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def process_image(image, ocr_type="ocr", ocr_box="", ocr_color=""):
    """
    ç”»åƒã‚’OCRå‡¦ç†
    
    Args:
        image: PIL Image ã¾ãŸã¯ç”»åƒãƒ‘ã‚¹
        ocr_type: OCRã‚¿ã‚¤ãƒ—ï¼ˆ"ocr", "format", "fine-grained"ï¼‰
        ocr_box: OCRãƒœãƒƒã‚¯ã‚¹åº§æ¨™ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        ocr_color: OCRè‰²æŒ‡å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    
    Returns:
        dict: OCRçµæœ
    """
    global model, tokenizer
    
    start_time = time.time()
    
    try:
        # ãƒ¢ãƒ‡ãƒ«æœªèª­ã¿è¾¼ã¿ã®å ´åˆã¯èª­ã¿è¾¼ã¿
        if model is None or tokenizer is None:
            if not load_model():
                raise Exception("ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # ç”»åƒå‡¦ç†
        if isinstance(image, str):
            # Base64æ–‡å­—åˆ—ã®å ´åˆ
            if image.startswith('data:image'):
                image = image.split(',')[1]
            image_data = base64.b64decode(image)
            image = Image.open(io.BytesIO(image_data))
        
        # PIL Imageã‚’RGBå½¢å¼ã«å¤‰æ›
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        logger.info(f"ç”»åƒã‚µã‚¤ã‚º: {image.size}")
        
        # OCRå‡¦ç†å®Ÿè¡Œ
        with torch.no_grad():
            result = model.chat(
                tokenizer, 
                image, 
                ocr_type=ocr_type,
                ocr_box=ocr_box,
                ocr_color=ocr_color
            )
        
        processing_time = time.time() - start_time
        
        logger.info(f"OCRå‡¦ç†å®Œäº†: {processing_time:.2f}ç§’, çµæœé•·: {len(result)}æ–‡å­—")
        
        return {
            "text": result,
            "confidence": 0.95,  # dots.ocrã¯é«˜ç²¾åº¦ãªã®ã§å›ºå®šå€¤
            "processing_time": processing_time,
            "model_used": "ucaslcl/GOT-OCR2_0",
            "device": str(device),
            "image_size": list(image.size)
        }
        
    except Exception as e:
        logger.error(f"OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        processing_time = time.time() - start_time
        
        return {
            "text": f"[ã‚¨ãƒ©ãƒ¼] OCRå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "confidence": 0.0,
            "processing_time": processing_time,
            "model_used": "error",
            "device": str(device),
            "error": str(e)
        }

def gradio_interface(image, ocr_type="ocr"):
    """Gradioç”¨ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹é–¢æ•°"""
    result = process_image(image, ocr_type=ocr_type)
    
    # çµæœã‚’æ•´å½¢ã—ã¦è¿”ã™
    output_text = result["text"]
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¿½åŠ 
    metadata = f"""
å‡¦ç†æ™‚é–“: {result['processing_time']:.2f}ç§’
ä¿¡é ¼åº¦: {result['confidence']:.1%}
ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {result['model_used']}
ãƒ‡ãƒã‚¤ã‚¹: {result['device']}
"""
    
    if 'image_size' in result:
        metadata += f"ç”»åƒã‚µã‚¤ã‚º: {result['image_size'][0]}x{result['image_size'][1]}"
    
    return output_text, metadata, json.dumps(result, ensure_ascii=False, indent=2)

def api_interface(image):
    """APIç”¨ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹é–¢æ•°ï¼ˆJSONè¿”å´ï¼‰"""
    result = process_image(image)
    return result

# Gradio ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¨­å®š
with gr.Blocks(
    title="dots.ocr (GOT-OCR2_0) - é«˜ç²¾åº¦OCR API",
    theme=gr.themes.Soft(),
    css="""
    .gradio-container {
        max-width: 1200px !important;
    }
    """
) as demo:
    gr.Markdown("""
    # ğŸ” dots.ocr (GOT-OCR2_0) - é«˜ç²¾åº¦OCR API
    
    æœ€å…ˆç«¯ã®è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹é«˜ç²¾åº¦OCRå‡¦ç†
    - **å¤šè¨€èªå¯¾å¿œ**: æ—¥æœ¬èªã€è‹±èªã€ä¸­å›½èªãªã©80ä»¥ä¸Šã®è¨€èª
    - **ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæ¤œå‡º**: ãƒ†ã‚­ã‚¹ãƒˆã€ãƒ†ãƒ¼ãƒ–ãƒ«ã€å›³è¡¨ã®æ§‹é€ èªè­˜
    - **é«˜ç²¾åº¦**: 95%ä»¥ä¸Šã®èªè­˜ç²¾åº¦
    
    ## ä½¿ç”¨æ–¹æ³•
    1. ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    2. OCRã‚¿ã‚¤ãƒ—ã‚’é¸æŠ
    3. ã€Œå‡¦ç†é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    """)
    
    with gr.Row():
        with gr.Column(scale=1):
            # å…¥åŠ›éƒ¨åˆ†
            image_input = gr.Image(
                type="pil",
                label="ğŸ“· ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                height=400
            )
            
            ocr_type = gr.Dropdown(
                choices=["ocr", "format", "fine-grained"],
                value="ocr",
                label="ğŸ”§ OCRã‚¿ã‚¤ãƒ—",
                info="ocr: åŸºæœ¬OCR, format: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¿æŒ, fine-grained: è©³ç´°è§£æ"
            )
            
            process_btn = gr.Button("ğŸš€ å‡¦ç†é–‹å§‹", variant="primary")
            
        with gr.Column(scale=2):
            # å‡ºåŠ›éƒ¨åˆ†
            with gr.Tab("ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆçµæœ"):
                text_output = gr.Textbox(
                    label="æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ",
                    lines=15,
                    placeholder="ã“ã“ã«æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™..."
                )
                
            with gr.Tab("ğŸ“Š å‡¦ç†æƒ…å ±"):
                metadata_output = gr.Textbox(
                    label="å‡¦ç†ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿",
                    lines=8,
                    placeholder="å‡¦ç†æ™‚é–“ã€ä¿¡é ¼åº¦ãªã©ã®æƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¾ã™..."
                )
                
            with gr.Tab("ğŸ”§ JSONçµæœ"):
                json_output = gr.Code(
                    label="å®Œå…¨ãªJSONçµæœ",
                    language="json"
                )
    
    # å‡¦ç†ãƒœã‚¿ãƒ³ã®ã‚¤ãƒ™ãƒ³ãƒˆè¨­å®š
    process_btn.click(
        fn=gradio_interface,
        inputs=[image_input, ocr_type],
        outputs=[text_output, metadata_output, json_output]
    )
    
    # APIç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    gr.Interface(
        fn=api_interface,
        inputs=gr.Image(type="pil"),
        outputs=gr.JSON(),
        title="API Endpoint",
        description="ã“ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ã®å‘¼ã³å‡ºã—ç”¨ã§ã™",
        api_name="ocr_api"
    )

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
if __name__ == "__main__":
    logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ä¸­...")
    
    # ç’°å¢ƒæƒ…å ±è¡¨ç¤º
    logger.info(f"PyTorch version: {torch.__version__}")
    logger.info(f"CUDA available: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        logger.info(f"CUDA version: {torch.version.cuda}")
        logger.info(f"GPU count: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            logger.info(f"GPU {i}: {torch.cuda.get_device_name(i)}")
    
    # ãƒ¢ãƒ‡ãƒ«äº‹å‰èª­ã¿è¾¼ã¿
    load_model()
    
    # Gradioã‚¢ãƒ—ãƒªèµ·å‹•
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,
        show_api=True
    )